{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 10 - NEURAL NETWORKS\n",
    "\n",
    "This lab is comprise of 2 examples:\n",
    "\n",
    " - 1. Example MNIST \n",
    "     - A) Neural Network\n",
    "     - B) Convolutional Neural Network\n",
    " - 2. Poker\n",
    " - 3. CTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(88)\n",
    "np.random.seed(88)\n",
    "tf.random.set_seed(88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6742\n",
       "7    6265\n",
       "3    6131\n",
       "2    5958\n",
       "9    5949\n",
       "0    5923\n",
       "6    5918\n",
       "8    5851\n",
       "4    5842\n",
       "5    5421\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1135\n",
       "2    1032\n",
       "7    1028\n",
       "3    1010\n",
       "9    1009\n",
       "4     982\n",
       "0     980\n",
       "8     974\n",
       "6     958\n",
       "5     892\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most dominant class is '1'. Therefore the baseline accuracy can be computed as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_acc = 0.1135\n"
     ]
    }
   ],
   "source": [
    "print('baseline_acc =', 1135/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAD7CAYAAAAFI30bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZAU9fnH8fcjUUQRBQ9EPMATUFE8USkkETwQxSOgBFSMEcsTLDWe8afx1sQK3qIiqFTQBAU0EiQK4oEGNKQih4JGdBUBTxAVgn5/f8x8e3rYnd3pnZme6dnPq2pre7p7th/m2W2e7v4e5pxDRETyt0G5AxARSRqdOEVEItKJU0QkIp04RUQi0olTRCQinThFRCIq6MRpZkeb2btmttjMrihWUFJeymv1Um6LwxrbjtPMmgHvAX2AGmA2MMg5N7944UnclNfqpdwWz88KeO9BwGLn3AcAZjYe6A/kTIKZNfXW9p8757YudxANUF6jS0JeIWJuldfceS3kUr098HHodU16neS2pNwB5EF5jS4JeQXlNqqceS2k4rQ61tX6H8rMhgHDCjiOxEt5rV4N5lZ5zU8hJ84aYIfQ6+2BT9ffyTk3ChgFKv0TQnmtXg3mVnnNTyGX6rOB3cyso5ltBJwKTC5OWFJGymv1Um6LpNEVp3NunZldAEwFmgGjnXPzihaZlIXyWr2U2+JpdHOkRh1Mpf9bzrkDyh1EsSmvymuVyplX9RwSEYlIJ04RkYgKeaouUlH233//YPmCCy4A4PTTTwfgscceA+Duu+8O9nn77bdjjE6qiSpOEZGIqvbhULNmzYLlzTffPOd+vjLZZJNNANhjjz0AOP/884N9/vCHPwAwaNAgAH744Ydg26233grA9ddfn09YeohQAvvuuy8AL730UrCuVatWde77zTffBMtbbrllsUJQXivIEUccAcC4ceMAOPzww4Nt7777bpQfpYdDIiLFohOniEhEiXw4tOOOOwbLG220EQCHHnooAD169ABgiy22CPY5+eST8/7ZNTU1ANx1113BuhNPPBGAVatWAfDvf/872Pbyyy9Hil2K56CDDgJgwoQJQPYtGX8Lyuds7dq1QPbleffu3YHMQyK/j+SvZ8+eQPbn+swzz5QrHAAOPPBAAGbPnl2yY6jiFBGJKFEVZ10PAep78BPFTz/9BMA111wDwLfffhts8zeZly5dCsBXX30VbIt4s1kayT+822+//YJ1TzzxBADt2rXL+b5FixYBcPvttwMwfvz4YNtrr70GZHJ+yy23FDHipqFXr14A7LbbbsG6clScG2yQqQE7duwIwE477QSAWV2DQhV4vKL/RBGRKpeoivOjjz4C4IsvvgjWRak433zzTQC+/vrrYN3Pf/5zIHN/6/HHHy84Tim+Bx98EMg0CcuXr1BbtmwJZN+T9tVS165dixBh0+Q7GMyaNauscYSvOs4++2wgc0WycOHCoh9PFaeISEQ6cYqIRNTgpbqZjQb6Acudc3ul17UBngQ6AB8CA51zX+X6GcXy5ZdfAnDZZZcF6/r16wfAv/71LyC7GZE3d+5cAPr06QPA6tWrg2177rknAMOHDy9BxJWrkvJaH9///NhjjwXqvtHvL7+fffbZYJ3v7fXpp6kBzv3vR/jB3i9+8YucPzPJ4sxt+KFMOT388MO11vkHg6WQz796DHD0euuuAF50zu0GvJh+LckyBuW1Wo1BuS2pBitO59xMM+uw3ur+QK/08lhgBnB5EeOq18SJE4Nl3zTJN3TeZ599ADjrrLOCfXz1Ea40vXnzUgNgDxvWtOanqsS8hvmmZ9OmTQMyfc/DYytMmTIFyDwwCvdJ9k2MfCWyYsUKILvzgm+C5qvZcFOnJI+cFEdu/QO1tm3bNvZHFFVdD4n9704pNPapelvn3FIA59xSM9sm146aNS9RlNfqlVduldf8lLw5UqlnzVu5cmXW6/DoN55vnvDkk08CmUpDGq8Ued19992DZX8f21cSn3/+OZDphAAwduxYINNZ4W9/+1uwLbzckBYtWgBwySWXBOsGDx4cKfZqkW9e+/btC2Q+u3LxFa9v9B72ySeflOy4jb2zu8zM2gGkvy8vXkhSRspr9VJui6ixFedk4Azg1vT3SUWLqEDXXXcdkD0auL/31bt3bwBeeOGF2ONKiLLktXnz5kDmXjRkKhp/79o3tJ4zZ06wT7GrnfDgMVWoqLn149Z6/llB3PzvTPhe63vvvQdkfndKocGK08z+DMwC9jCzGjM7i9SH38fMFgF90q8lQZTX6qXcll4+T9Vz9XE7osixSIyU1+ql3JZeovqq58M3OfIPhCDTtOShhx4CYPr06cE2f+l37733AtnNXSQe3bp1AzKX52H9+/cHNO5ppSvl2JfhaVCOPjrVPHXIkCEAHHnkkbX2v+GGG4DsMSmKrTKa/YuIJEjVVZze+++/HywPHToUgEcffRSA0047LdjmlzfddFMgM41suNmLlNadd94JZHd99BVmKStN311QzdMK16ZNm7z28x1UfK79A9vtt98+2MfP6uCbhIW7dX7//fdAZqSzNWvWAPCzn2VOZW+99Vb0f0BEqjhFRCKq2oozzI9I7Tv9+woHMlOJ3nzzzUBm1Oibbrop2KeUDWmbMj9Ai+9eGb6/PHny5JIf31ea/rh+MBhpmK/8/Gf3wAMPBNuuuuqqnO/zXTV9xblu3ToAvvvuu2Cf+fPnAzB69GgguwmavwJZtmwZkJkjLNw0rRTjb65PFaeISEQ6cYqIRNQkLtW9d955B4CBAwcG64477jgg8+DonHPOAbInn/LjeEpx+csr/zBg+fJML0A/rkCx+N5JvmdZmB9h68orryzqMavZeeedB8CSJUuAzPTcDfHT3/gRzhYsWADAG2+8Een4fjSzrbfeGoAPPvgg0vsLpYpTRCSiJlVxeuGGsX5yNj9uo2/W0LNnz2AfP6nXjBkz4gmwifJNS6B4zcF8penH5wzPHuAfLPzxj38EsqeElvzcdtttZTmuf6jrTZgwIdbjq+IUEYmoSVWcvinEL3/5y2DdgQceCGQ3oIVMkwiAmTNnxhCdFLMJkm/i5CvMU045BYBJkzKDAp188slFO56Ul29yGBdVnCIiEVVtxRkeL/CCCy4A4KSTTgJg2223zfm+H3/8Eci+x6YueaXhG0H77yeccEKwrTGzjl588cXB8u9+9zsgM4L8uHHjgMy4niKFyGc8zh3MbLqZLTCzeWY2PL2+jZlNM7NF6e+tSx+uFIvyWp2U13jkc6m+DrjEOdcZ6A6cb2Zd0HSjSae8ViflNQb5DGS8FPCz460yswVAeypoKlnIXH77qWL95TlAhw4dGny/7w/r+6jH0Ve6nCohr76fs/8evoVy1113AZn+yl988QUA3bt3D/bxI1v5EXfCI+z4htZTp04F4L777iv+P6ACVUJe4+Rv84Qn+ovamL4xIt3jTM/V3A14E003WjWU1+qkvJZO3idOM2sJTABGOOdWhsdOrE8pppENT8zUpUsXAO655x4AOnXq1OD7/Vh+AHfccQeQaabS1B4EVVJemzVrFiz7Ln2+yZCfBjrcFXZ9r7/+erDsR/m/9tprixFa4lRSXkvJX62Ex+yMQ15HM7MNSSVhnHPu6fRqTTeacMprdVJeS6/BitNS/1U9Aixwzt0Z2hTbVLJ+dOkHH3wQyDRuBth5550bfL+vRHzXOn/fCzLjCjY1lZDXWbNmAZn5anxnhDB/3zN8leH5+57jx48HGteEqdpUQl7L4ZBDDgmWx4wZU/Lj5XOpfhhwGvAfM/MjvV5FKgFPpace/QgYUJoQpUSU1+qkvMYgn6fqrwK5bpBoutGEUl6rk/Iaj4rrOXTwwQcD2aPYHHTQQQC0b9++wff7Ifh9cxbITIvhpw6WyuBHJ/I9uvxYqJAZzWh9I0eODJbvv/9+ABYvXlyqEKXC5fvQq9jUV11EJKKKqzhPPPHErO91CY9c9NxzzwGZSZ/8A6BSTkYvxeXHBQiPzl7XSO0i3pQpUwAYMKA8t2pVcYqIRGThKVlLfrAENKgtsbeccweUO4hiU16V1yqVM6+qOEVEItKJU0QkIp04RUQi0olTRCQinThFRCLSiVNEJKK4G8B/DqxOf0+arSg87p2KEUgFUl6rk/KaQ6ztOAHMbE4S27wlNe64JPXzSWrccUnq51PquHWpLiISkU6cIiIRlePEOaoMxyyGpMYdl6R+PkmNOy5J/XxKGnfs9zhFRJJOl+oiIhHpxCkiElFsJ04zO9rM3jWzxWZ2RVzHjcrMdjCz6Wa2wMzmmdnw9Po2ZjbNzBalv7cud6yVIgm5VV6jU17rOW4c9zjNrBnwHtAHqAFmA4Occ/PrfWMZpOecbuece9vMNgPeAk4AhgJfOuduTf8StXbOXV7GUCtCUnKrvEajvNYvrorzIGCxc+4D59xaYDzQP6ZjR+KcW+qcezu9vApYALQnFe/Y9G5jSSVHEpJb5TUy5bUeBZ04I5Ty7YGPQ69r0usqmpl1ALoBbwJtnXNLIZUsYJvyRVZaES/REpfbpppXqO6/2Tjz2ugTZ7qUvxc4BugCDDKzLrl2r2NdRbeDMrOWwARghHNuZbnjiUvEvELCcttU8wrV/Tcbe16dc436Ag4BpoZeXwlcWd++pD74pvy1orGfd1xfUfIa2r/cn2u5vyo+r438my3351rur5x5LWR0pLpK+YPX38nMhgHDgL0LOFa1WFLuAPIQNa+SjLxCHrlVXrPkzGsh9zjzKuWdc6NcapSS3BOlSyWJlFeXwJFzmrAGc6u85qeQE2cNsEPo9fbAp7l2ds49X8CxJD6R8iqJotwWSSEnztnAbmbW0cw2Ak4FJhcnLCkj5bV6KbdF0uh7nM65dWZ2AamHPs2A0c65eUWLTMpCea1eym3xxDo6kpnFd7DK9FY13jtSXpXXKpUzrxrkQ0QkIp04RUQi0olTRCQinThFRCKKe171infNNdcAcP311wfrNtgg9f9Lr169AHj55Zdjj0ukqdpss82C5ZYtWwJw7LHHArD11lsDcOeddwb7rFmzpuQxqeIUEYlIJ04RkYh0qZ42dOhQAC6/PDVI9E8//VRrnzjbvIo0VR06dAAyf4uHHHJIsG2vvfaq8z3t2rULli+66KLSBZemilNEJCJVnGk77bQTABtvvHGZI5H6HHxwZhS0IUOGAHD44YcDsOeee9ba/9JLLwXg009TY1n06NEj2PbEE08A8Oabb5YmWGlQp06dABgxYkSwbvDgwQC0aNECALPMoE4ff5waFW/VqlUAdO7cGYCBAwcG+9x3330ALFy4sFRhq+IUEYmqyVecvXv3BuDCCy/MWh/+36pfv34ALFu2LL7AJMspp5wCwMiRI4N1W221FZCpSGbMmBFs881U7rjjjqyfE65e/D6nnnpq8QOWOm2++eYA3HbbbUAmr+EmR+tbtGhRsHzUUUcBsOGGGwKZv1P/u7D+cqmo4hQRiUgnThGRiBq8VDez0UA/YLlzbq/0ujbAk0AH4ENgoHPuq9KFWVzhBwSPPvookLmE8MKXeEuWJGVKmfxVel5/9rPUr+YBB6RG9XrooYcA2GSTTYJ9Zs6cCcANN9wAwKuvvhpsa968OQBPPfUUAEceeWStY8yZM6fYYVeESs7tiSemZtD5zW9+0+C+77//PgB9+vQJ1vmHQ7vuumsJostfPhXnGODo9dZdAbzonNsNeDH9WpJlDMprtRqDcltSDVaczrmZ6Ynew/oDvdLLY4EZwOVFjKukzjjjjGB5u+22y9rmHzA89thjcYYUu0rPq29q9PDDD2etnzZtWrDsHyysXFl7Gm2/bf1Ks6amJlgeO3ZscYKtMJWc2wEDBtS5/sMPPwyWZ8+eDWQawPsqM8w3QyqXxj5Vb+ucWwrgnFtqZtvk2lHTjSaK8lq98sqt8pqfkjdHcs6NAkZB+Yfi980Ufv3rXwfrfNfKr7/+GoAbb7wx/sASqBR59fcqAa666ip/HCDTqNmPXgV1V5re1VdfXef6cHe8FStWND7YKlXqv9ezzz4bgGHDUufmF154AYDFixcH+yxfvrzBn9O2bdtihxZJY5+qLzOzdgDp7w3/SyUJlNfqpdwWUWMrzsnAGcCt6e+TihZRCfhBAyZMmJBzn7vvvhuA6dOnxxFSpSpLXq+99logU2UCrF27FoCpU6cCmftd33//fa33+26y4fuZO+64I5Bp8O6vJCZNquhf1VKqiL9Z3/X1uuuuK+jnhAf+KIcGK04z+zMwC9jDzGrM7CxSH34fM1sE9Em/lgRRXquXclt6+TxVH5Rj0xFFjkVipLxWL+W29JpEX/Wjj041aevatWutbS+++CKQ3Qda4rHFFlsAcN555wHZ4536S/QTTjgh5/t9I+hx48YBsP/++9fa569//SsAt99+exEiljj4B3ibbrppzn323nvvrNevv/56sDxr1qzSBBaiLpciIhFVbcUZrlRuvTX7dk64a55vDP/NN9/EE5gENtpoI6Du0Wx81bHNNqnmhmeeeSYAxx9/fLCPHw3cT+AVrlj9sh9zc/Xq1UWNXQrju8526dIFgP/7v/8LtvXt2zdrXz9ZItSemcE/bPK/HwA//vhjcYOtgypOEZGIqq7izKfp0QcffBAsa4zN8vFNjnxDdD8+JsB///tfoP55nny14RvCh+ed+fzzzwF49tlnixixNIYfOxOgW7duQObv0+cs3MzM59Xfq/TPKCB7kBfIDAZz0kknBev88wr/+1UKqjhFRCLSiVNEJKKqu1Svb3pfb/2HRVIefnwA/yDvueeeC7a1adMGyIzJ6Hv8jBkzJtjnyy+/BGD8+PFA9qW6Xyfl4x/+hS+1n3766ax9rr/+egBeeumlYN1rr70GZH4HwtvWnx7Y39655ZZbgnUfffQRABMnTgRgzZo1Bfwr6qaKU0QkoqqpOPfdd1+g7pG+PV+1vPvuu7HEJPnx0/OGHw7lo2fPnkBmeuDwVUb4AaDEyz8M8tXkZZddVmufKVOmAJkxIvzVB2R+D55//nkgu7G7f+DjOzT4CrR///7BPr5DxD/+8Q8gMzEcwFdfZQ96P3fu3Aj/sgxVnCIiEVVNxenH9WvdunWtbW+88QYAQ4cOjTMkKbEWLVoAmUoz3HRJ9zjj1axZs2DZj6t66aWXAtmdD664IjVjh8+PrzT93FIA99xzD5BpuhSeHvjcc88FMqOYtWrVCoBDDz002Gfw4MFAprNEeNYAz48q37Fjx7z/jWGqOEVEIqqainPLLbcE6n6a7kcP//bbb2ONSUrLDwQi5edHdIdMpfndd98BcM455wTb/JVh9+7dgUxXyWOOOSbYx19J/P73vwcyM9FC7fmHfOeHv//978E6vzxoUGqQqF/96le14r344ovz/JfVLZ/xOHcws+lmtsDM5pnZ8PT6NmY2zcwWpb/XvkaWiqW8ViflNR75XKqvAy5xznUGugPnm1kXNN1o0imv1Ul5jYHV1xe4zjeYTQLuSX/1Ss+Y1w6Y4Zzbo4H3Fn3yJ1/G+wc/dV2q77zzzgAsWbKk2IeP6i3n3AEN7xa/SstrPo466igg02wl/LvsG8PHNCFbk8/r0qVLg2XfnMg3PF+4cGGwzY+x6cdSrYufVsM3ao9jtKMccuY10j3O9FzN3YA30XSjVUN5rU7Ka+nkfeI0s5bABGCEc26lnwSrIaWYbtQ3dgfo3bs3kKk0fQPZe++9N9hHIyDlVkl5jcpfSUhtcef1s88+C5Z9xdm8eXMA9tlnn1r7+6uEmTNnApnukQAffvghUNZKs0F5NUcysw1JJWGcc853NtV0owmnvFYn5bX0Gqw4LfVf1SPAAufcnaFNZZtu1M9VA7Dttttmbfvkk0+ATJMIqVsl5jWqV155BciMEF7fwC5NRbny6ru/QmbQlv322w+A5csz5+jRo0cDma6PpRwzs5TyuVQ/DDgN+I+Z+Y6dV5FKwFPpqUc/AgaUJkQpEeW1OimvMchneuBXgVw3SDTdaEIpr9VJeY1H1fQckqbnnXfeATJ9mcMPi3bZZRcgtuZITd6qVauC5ccffzzrezVSX3URkYgSWXGGG9T6ieh79OhRrnCkzG6++WYAHn744WDdTTfdBMCFF14IwPz58+MPTKqWKk4RkYgid7ks6GBlaihdQSq2a14hyp1XPybjU089FazzHSP8HDd+FJ7w2JBFpLxWp5x5VcUpIhKRKs54qTIpIV95QuYepx8xvGvXrkDJ7nUqr9VJFaeISLHoxCkiEpEu1eOlS7rqpLxWJ12qi4gUS9wN4D8HVqe/J81WFB73TsUIpAIpr9VJec0h1kt1ADObk8TLmqTGHZekfj5JjTsuSf18Sh23LtVFRCLSiVNEJKJynDhHleGYxZDUuOOS1M8nqXHHJamfT0njjv0ep4hI0ulSXUQkIp04RUQiiu3EaWZHm9m7ZrbYzK6I67hRmdkOZjbdzBaY2TwzG55e38bMppnZovT31uWOtVIkIbfKa3TKaz3HjeMep5k1A94D+gA1wGxgkHOu4oblTs853c4597aZbQa8BZwADAW+dM7dmv4lau2cu7yMoVaEpORWeY1Gea1fXBXnQcBi59wHzrm1wHigf0zHjsQ5t9Q593Z6eRWwAGhPKt6x6d3GkkqOJCS3ymtkyms9CjpxRijl2wMfh17XpNdVNDPrAHQD3gTaOueWQipZwDbli6y0Il6iJS63TTWvUN1/s3HmtdEnznQpfy9wDNAFGGRmXXLtXse6im4HZWYtgQnACOfcynLHE5eIeYWE5bap5hWq+2829rw65xr1BRwCTA29vhK4sr59SX3wTflrRWM/77i+ouQ1tH+5P9dyf1V8Xhv5N1vuz7XcXznzWsjoSHWV8gevv5OZDQOGAXsXcKxqsaTcAeQhal4lGXmFPHKrvGbJmddC7nHmVco750a51CglJxZwLIlPpLy6BI6c04Q1mFvlNT+FnDhrgB1Cr7cHPs21s3Pu+QKOJfGJlFdJFOW2SAo5cc4GdjOzjma2EXAqMLk4YUkZKa/VS7ktkkbf43TOrTOzC0g99GkGjHbOzStaZFIWymv1Um6LR5O1xUuTelUn5bU6abI2EZFi0YlTRCSiuGe5jM3IkSOD5YsuugiAd955B4B+/foF25YsSUoTPBGpFKo4RUQiqrqKs0OHDgAMGTIkWPfTTz8B0LlzZwA6deoUbFPFmQy77747ABtuuGGwrmfPngDcd999QCbP+Zo0aRIAp556KgBr164tOE5pnHBeDz30UABuvvlmAA477LCyxFQfVZwiIhHpxCkiElHVXaqvWLECgJkzZwbrjj/++HKFI4205557AjB06FAABgwYAMAGG2T+r99uu+2AzCV61DbJ/vfigQceAGDEiBHBtpUrm9SIc2W3+eabB8vTp08H4LPPPgNg2223Dbb5deWmilNEJKKqqzhXr14N6KFP0t1yyy0A9O3bt+THOv300wF45JFHgnWvvfZayY8r9fOVpipOEZEqUHUV5xZbbAHAPvvsU+ZIpBDTpk0Dalecy5cvD5Z9hejve9bVHMk3bTn88MNLEqeUjlldw4dWBlWcIiIR6cQpIhJRg5fqZjYa6Acsd87tlV7XBngS6AB8CAx0zn1VujDzt8kmmwCw44475tznwAMPDJYXLlwINL2HSZWe1/vvvx+AiRMnZq3/3//+Fyzn86CgVatWQGacAt+EKcwfY86cOY0LtsJUem7z5ZuXbbzxxmWOpLZ8Ks4xwNHrrbsCeNE5txvwYvq1JMsYlNdqNQbltqQarDidczPTE72H9Qd6pZfHAjOAy4sYV6N9+mlqCpUxY8YE66677rqsfcKvv/76awDuueeeUodWUSo9r+vWrQPg448/bmDP+h111FEAtG7dOuc+NTU1AKxZs6agY1WKSs9tVAcckBlL+I033ihjJBmNfare1jm3FMA5t9TMtsm1o6YbTRTltXrllVvlNT8lb47knBsFjIJ4h+K/4YYbguX1K04pXLnymi8/4tHZZ58NQIsWLXLue+2118YSUxKUK6/+CgPgm2++ATLdMHfZZZe4wshbY5+qLzOzdgDp78sb2F+SQXmtXsptETW24pwMnAHcmv4+qWgRlUB9DaQlS6Ly6g0ePBiAK67IPO/YddddgexxHtc3d+5cIPtJfRWr6Nz6Zw0Ar7zyCpA9U0OlabDiNLM/A7OAPcysxszOIvXh9zGzRUCf9GtJEOW1eim3pZfPU/VBOTYdUeRYJEbKa/VSbkuv6vqq16Wx4zVK+fgpUE477TQAevfunXPfHj16APXn14+vGb6cf/755wH4/vvvC4pVmh51uRQRiahJVJySDHvttVewPHnyZKD+rrNR+AcOo0aNKsrPk/hsueWW5Q6hFlWcIiIRqeKUiuTHYsxnTMZ8mpv5pi3HHHNMsG7KlCmFhCgxqcQ5w1RxiohEpBOniEhETeJSvb5LuZ49ewJNb3SkSuTHzATo1asXAEOGDAFg6tSpAPzwww95/ayzzjoLgAsvvLCIEUoc/PTAie45JCIi2SzORuHlGkXnxx9/BOpvIN21a1cA5s+fX8pQ3nLOHdDwbslSiaMj+ZF1vvjii6z1xx13XLBcxIdDymsRnXzyyQD85S9/AbI7KHTp0gWIbcaGnHlVxSkiElGTuMf5wAMPAHDOOefk3GfYsNTYrSNGjIglJiktP/K7JE94bE7IbpLWvHnzuMOpkypOEZGI8pnlcgfgMWBb4CdglHNuZJJmzfMzWUpGJeTVj5V55JFHAvDSSy8F2xoz8MaZZ54ZLI8cObLA6JKpEvJaqEmTUkOF+r/bTp06Bdv8FeF5550Xf2Ah+VSc64BLnHOdge7A+WbWBc2al3TKa3VSXmPQ4InTObfUOfd2enkVsABoT2rWvLHp3cYCJ5QqSCk+5bU6Ka/xiNQcKT3l6ExgL+Aj59wWoW1fOedyz8FK+ZutvPfee0Ddkz/5RvJ+yoX333+/FCFUZLOVOPPqx84EuPrqqwHo06cPAB07dgy25TMtcJs2bQDo27cvAHfffXewbbPNNsva11/6h/s9+4bWRdDk81oKf/rTn4DsWzBt27YF8u8IUaCcec37qbqZtQQmACOccw9ILkIAAAP/SURBVCvzGXwh/T5NN1rBlNfqpLyWVl4nTjPbkFQSxjnnnk6vXmZm7dJzNOecNa+SppGdN28eADvvvHOtbU1xIrdy5DXctTU8/ibAb3/722B51apVDf4sX6nut99+PqZa+8yYMQOA+++/HyhqlVmxquXv1Qvnde3atWWMJCOfydoMeARY4Jy7M7TJz5oHFThrntRPea1Oyms88qk4DwNOA/5jZnPT664iNUveU+kZ9D4CBpQmxOLxo3+Hu901YRWX13PPPbeg9y9fniminn32WQCGDx8OxHZPrBJUXF4L1apVq2C5f//+ADzzzDPlCgfIb5bLV4FcN0g0a15CKa/VSXmNh3oOiYhE1CT6qnt+5KMFCxYE6zp37lyucJqkoUOHBst+rMwzzjgjx961hZuJfffdd0DdE7GFx/aUZBo4cCAAa9asCdaF/3bLSRWniEhETari9GP47b333mWOpOmaO3dusOz7G//zn/8E4MYbbwy2tW6daps9ceJEAKZNmwZk+jEDfPbZZ6UNVspq5syZQPZVYWPGMCgFVZwiIhE1iRHgK0hFds0rlPKqvFYpjQAvIlIsOnGKiESkE6eISEQ6cYqIRKQTp4hIRDpxiohEFHcD+M+B1envSbMVhce9UzECqUDKa3VSXnOItR0ngJnNSWKbt6TGHZekfj5JjTsuSf18Sh23LtVFRCLSiVNEJKJynDhHNbxLRUpq3HFJ6ueT1LjjktTPp6Rxx36PU0Qk6XSpLiISUWwnTjM72szeNbPFZnZFXMeNysx2MLPpZrbAzOaZ2fD0+jZmNs3MFqW/ty53rJUiCblVXqNTXus5bhyX6mbWDHgP6APUALOBQc65+SU/eETpOafbOefeNrPNgLeAE4ChwJfOuVvTv0StnXOXlzHUipCU3Cqv0Siv9Yur4jwIWOyc+8A5txYYD/SP6diROOeWOufeTi+vAhYA7UnFOza921hSyZGE5FZ5jUx5rUdcJ872wMeh1zXpdRXNzDoA3YA3gbbOuaWQShawTfkiqyiJy63ymhfltR5xnTjrmue5oh/nm1lLYAIwwjm3stzxVLBE5VZ5zZvyWo+4Tpw1wA6h19sDn8Z07MjMbENSSRjnnHs6vXpZ+n6Kv6+yvFzxVZjE5FZ5jUR5rUdcJ87ZwG5m1tHMNgJOBSbHdOxIzMyAR4AFzrk7Q5smA34C8DOASeu/t4lKRG6V18iU1/qOG1cDeDPrC/wJaAaMds7dFMuBIzKzHsArwH+An9KrryJ13+QpYEfgI2CAc+7LsgRZYZKQW+U1OuW1nuOq55CISDTqOSQiEpFOnCIiEenEKSISkU6cIiIR6cQpIhKRTpwiIhHpxCkiEpFOnCIiEf0/A8Ygy5MDWnYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    \n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the image data into length 28*28 = 784 feature vectors, then normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reshaped = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "# X_train_reshaped = X_train.reshape(-1, 28*28)\n",
    "X_train_normalized = X_train_reshaped/255\n",
    "X_train_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_reshaped = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "# X_test_reshaped = X_test.reshape(-1, 28*28)\n",
    "X_test_normalized = X_test_reshaped/255\n",
    "X_test_normalized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert labels to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.4753 - accuracy: 0.8621 - val_loss: 0.1441 - val_accuracy: 0.9591\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1308 - accuracy: 0.9612 - val_loss: 0.1052 - val_accuracy: 0.9686\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0790 - accuracy: 0.9769 - val_loss: 0.0972 - val_accuracy: 0.9724\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0544 - accuracy: 0.9839 - val_loss: 0.0838 - val_accuracy: 0.9753\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0411 - accuracy: 0.9880 - val_loss: 0.0801 - val_accuracy: 0.9767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bf390cabc8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "## Defining the model\n",
    "# A Sequential model is appropriate for a plain stack of layers \n",
    "# where each layer has exactly one input tensor and one output tensor.\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28, 1)))\n",
    "model.add(Dense(512, activation='relu')) #, input_shape=(28, 28, 1)))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "## Compiling the model\n",
    "opt = RMSprop()\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "## Training the model\n",
    "model.fit(X_train_normalized,\n",
    "          y_train_encoded,\n",
    "          epochs=5,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0687 - accuracy: 0.9799\n",
      "0.9799000024795532\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test_normalized, y_test_encoded)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "750/750 [==============================] - 28s 36ms/step - loss: 0.4551 - accuracy: 0.8541 - val_loss: 0.0551 - val_accuracy: 0.9836\n",
      "Epoch 2/5\n",
      "750/750 [==============================] - 27s 36ms/step - loss: 0.0568 - accuracy: 0.9822 - val_loss: 0.0461 - val_accuracy: 0.9862\n",
      "Epoch 3/5\n",
      "750/750 [==============================] - 32s 43ms/step - loss: 0.0358 - accuracy: 0.9885 - val_loss: 0.0468 - val_accuracy: 0.9867\n",
      "Epoch 4/5\n",
      "750/750 [==============================] - 31s 42ms/step - loss: 0.0270 - accuracy: 0.9917 - val_loss: 0.0438 - val_accuracy: 0.9868\n",
      "Epoch 5/5\n",
      "750/750 [==============================] - 33s 43ms/step - loss: 0.0221 - accuracy: 0.9943 - val_loss: 0.0378 - val_accuracy: 0.9903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bf394a2f48>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = RMSprop()\n",
    "model2.compile(optimizer=opt,\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model2.fit(X_train_normalized,\n",
    "           y_train_encoded,\n",
    "           epochs=5,\n",
    "           batch_size=64,\n",
    "           validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0293 - accuracy: 0.9906\n",
      "0.9905999898910522\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model2.evaluate(X_test_normalized, y_test_encoded)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25010 entries, 0 to 25009\n",
      "Data columns (total 11 columns):\n",
      "S1      25010 non-null int64\n",
      "C1      25010 non-null int64\n",
      "S2      25010 non-null int64\n",
      "C2      25010 non-null int64\n",
      "S3      25010 non-null int64\n",
      "C3      25010 non-null int64\n",
      "S4      25010 non-null int64\n",
      "C4      25010 non-null int64\n",
      "S5      25010 non-null int64\n",
      "C5      25010 non-null int64\n",
      "hand    25010 non-null int64\n",
      "dtypes: int64(11)\n",
      "memory usage: 2.1 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>C1</th>\n",
       "      <th>S2</th>\n",
       "      <th>C2</th>\n",
       "      <th>S3</th>\n",
       "      <th>C3</th>\n",
       "      <th>S4</th>\n",
       "      <th>C4</th>\n",
       "      <th>S5</th>\n",
       "      <th>C5</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S1  C1  S2  C2  S3  C3  S4  C4  S5  C5  hand\n",
       "0   4   9   2   1   2   2   4   7   2   8     0\n",
       "1   1   4   3   6   1  12   3  11   2   7     0\n",
       "2   1  11   4   1   3   7   4  11   2   1     2\n",
       "3   2   9   2   4   3   6   1   9   4   9     3\n",
       "4   1   8   2   4   2  11   2   2   2   1     0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poker = pd.read_csv('train.csv')\n",
    "\n",
    "# pd.set_option('display.max_rows', 200)\n",
    "# pd.set_option('display.max_columns', 200)\n",
    "poker.info()\n",
    "poker.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in poker:\n",
    "#    poker[i] = poker[i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poker_encoded = pd.get_dummies(poker, dtype=float)\n",
    "#poker_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25010, 11)\n",
      "(17507, 11)\n",
      "(7503, 11)\n"
     ]
    }
   ],
   "source": [
    "train = poker.sample(frac=0.7, random_state=88)\n",
    "test = poker.drop(train.index)\n",
    "\n",
    "print(poker.shape)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>hand</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25005</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25006</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7503 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "hand   0  1  2  3  4  5  6  7  8  9\n",
       "1      1  0  0  0  0  0  0  0  0  0\n",
       "7      1  0  0  0  0  0  0  0  0  0\n",
       "12     1  0  0  0  0  0  0  0  0  0\n",
       "15     1  0  0  0  0  0  0  0  0  0\n",
       "16     0  1  0  0  0  0  0  0  0  0\n",
       "...   .. .. .. .. .. .. .. .. .. ..\n",
       "25002  1  0  0  0  0  0  0  0  0  0\n",
       "25005  0  1  0  0  0  0  0  0  0  0\n",
       "25006  1  0  0  0  0  0  0  0  0  0\n",
       "25008  1  0  0  0  0  0  0  0  0  0\n",
       "25009  0  1  0  0  0  0  0  0  0  0\n",
       "\n",
       "[7503 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "y_train = train['hand'].astype('category')\n",
    "X_train = train.drop(columns=['hand'])\n",
    "\n",
    "y_test = test['hand'].astype('category')\n",
    "y_test_add = y_test.cat.add_categories('9')\n",
    "X_test = test.drop(columns=['hand'])\n",
    "\n",
    "ohe = OneHotEncoder(drop = 'first')\n",
    "ohe.fit(X_train)\n",
    "X_train_encoded = ohe.transform(X_train).toarray()\n",
    "X_test_encoded = ohe.transform(X_test).toarray()\n",
    "\n",
    "\n",
    "y_train_encoded = pd.get_dummies(y_train)\n",
    "y_test_encoded = pd.get_dummies(y_test_add)\n",
    "y_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8731\n",
       "1    7409\n",
       "2     854\n",
       "3     376\n",
       "4      65\n",
       "5      35\n",
       "6      25\n",
       "9       5\n",
       "7       4\n",
       "8       3\n",
       "Name: hand, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline\n",
    "pd.Series(train['hand']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3762\n",
       "1    3190\n",
       "2     352\n",
       "3     137\n",
       "4      28\n",
       "5      19\n",
       "6      11\n",
       "7       2\n",
       "8       2\n",
       "Name: hand, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(test['hand']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most dominant class is '0', the baseline accuracy would predict that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_acc = 0.5013994402239105\n"
     ]
    }
   ],
   "source": [
    "print('baseline_acc =', 3762/len(test['hand']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_encoded = train_encoded['hand']\n",
    "#X_train_encoded = train_encoded.drop(columns=['hand'])\n",
    "\n",
    "#y_test_encoded = test_encoded['hand']\n",
    "#X_test_encoded = test_encoded.drop(columns=['hand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# enc = OneHotEncoder(handle_unknown='ignore')\n",
    "# X_train_encoded = enc.fit_transform(X_train_encoded.reshape(-1, 1))\n",
    "# X_train_encoded.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.4910035985605758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train_encoded, y_train)\n",
    "\n",
    "y_prob_lda = lda.predict_proba(X_test_encoded)\n",
    "# y_pred_lda = pd.Series([1 if x > 1/2 else 0 for x in y_prob_lda[:,1]], index=y_test_encoded.index)\n",
    "y_pred_lda = lda.predict(X_test_encoded)\n",
    "\n",
    "print (\"\\nAccuracy:\", accuracy_score(y_test, y_pred_lda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest time: 7.46 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "rf = RandomForestClassifier(max_features=5, min_samples_leaf=5, n_estimators = 500, random_state=88)\n",
    "rf.fit(X_train_encoded, y_train)\n",
    "\n",
    "toc = time.time()\n",
    "print('Random Forest time:', round(toc-tic, 2),'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.6309476209516194\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = rf.predict(X_test_encoded)\n",
    "\n",
    "print (\"\\nAccuracy:\", accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_encoded.head()\n",
    "#X_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep for Keras\n",
    "#trainX <- model.matrix(hand ~ . , data = train.poker)\n",
    "#trainX = trainX[,2:76]\n",
    "#trainY <- model.matrix(~ hand -1, data = train.poker)\n",
    "\n",
    "#testX <- model.matrix(hand ~ . , data = test.poker)\n",
    "#testX = testX[,2:76]\n",
    "#testY <- model.matrix(~ hand -1, data = test.poker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Hidden Layer Model Sigmoid\n",
    "\n",
    "Sequential models are created using the `Sequential()` function and are composed of a set of linear layers.\n",
    "\n",
    "Add A Densely-Connected NN Layer To An Output using `Dense()`\n",
    "\n",
    "It has arguments object: model, units: number of units, input_shape: Dimensionality of the input, activation: choose activation function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import Input\n",
    "from keras.layers import Dense\n",
    "\n",
    "## Defining the model\n",
    "nn_mod_1 = Sequential()\n",
    "nn_mod_1.add(Input(shape=(75,)))\n",
    "nn_mod_1.add(Dense(100, activation='sigmoid')) #, input_shape=(75)))\n",
    "nn_mod_1.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training a model, we need to configure the learning process, which is done via the compile() function.\n",
    "It receives three arguments:\n",
    "1. An optimizer. \n",
    "This could be the string identifier of an existing optimizer (e.g. as “rmsprop” or “adagrad”) or a call to an optimizer function (e.g. optimizer_sgd()).\n",
    "2. A loss function. \n",
    "This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function (e.g. “categorical_crossentropy” or “mse”) or a call to a loss function (e.g. loss_mean_squared_error()).\n",
    "3. A list of metrics. \n",
    "For any classification problem you will want to set this to metrics = c('accuracy'). A metric could be the string identifier of an existing metric or a call to metric function (e.g. metric_binary_crossentropy()).\n",
    "\n",
    "rmsprop is basiclly : Divide the gradient by a running average of its recent magnitude. You can google it to get more information.\n",
    "Consider it as a sophisticated way to get gradient in gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compiling the model\n",
    "opt = RMSprop()\n",
    "nn_mod_1.compile(optimizer=opt,\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.1536 - accuracy: 0.4528 - val_loss: 1.0237 - val_accuracy: 0.4800\n",
      "Epoch 2/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 1.0012 - accuracy: 0.5040 - val_loss: 1.0321 - val_accuracy: 0.4786\n",
      "Epoch 3/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9981 - accuracy: 0.4985 - val_loss: 1.0248 - val_accuracy: 0.4792\n",
      "Epoch 4/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.9800 - accuracy: 0.4931 - val_loss: 1.0254 - val_accuracy: 0.4832\n",
      "Epoch 5/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9886 - accuracy: 0.4946 - val_loss: 1.0257 - val_accuracy: 0.4786\n",
      "Epoch 6/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.9790 - accuracy: 0.4995 - val_loss: 1.0226 - val_accuracy: 0.4743\n",
      "Epoch 7/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9799 - accuracy: 0.5061 - val_loss: 1.0262 - val_accuracy: 0.4792\n",
      "Epoch 8/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.9955 - accuracy: 0.5034 - val_loss: 1.0259 - val_accuracy: 0.4555\n",
      "Epoch 9/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.9874 - accuracy: 0.5008 - val_loss: 1.0255 - val_accuracy: 0.4535\n",
      "Epoch 10/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.9868 - accuracy: 0.5028 - val_loss: 1.0272 - val_accuracy: 0.4592\n",
      "Epoch 11/100\n",
      "438/438 [==============================] - 0s 986us/step - loss: 0.9816 - accuracy: 0.5133 - val_loss: 1.0271 - val_accuracy: 0.4823\n",
      "Epoch 12/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9703 - accuracy: 0.5007 - val_loss: 1.0266 - val_accuracy: 0.4834\n",
      "Epoch 13/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.9741 - accuracy: 0.5029 - val_loss: 1.0264 - val_accuracy: 0.4846\n",
      "Epoch 14/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9746 - accuracy: 0.5128 - val_loss: 1.0258 - val_accuracy: 0.4854\n",
      "Epoch 15/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9738 - accuracy: 0.5174 - val_loss: 1.0188 - val_accuracy: 0.4949\n",
      "Epoch 16/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9713 - accuracy: 0.5150 - val_loss: 1.0208 - val_accuracy: 0.4920\n",
      "Epoch 17/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9732 - accuracy: 0.5179 - val_loss: 1.0155 - val_accuracy: 0.5017\n",
      "Epoch 18/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.9775 - accuracy: 0.5240 - val_loss: 1.0126 - val_accuracy: 0.5097\n",
      "Epoch 19/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9816 - accuracy: 0.5306 - val_loss: 1.0122 - val_accuracy: 0.5123\n",
      "Epoch 20/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9549 - accuracy: 0.5421 - val_loss: 1.0073 - val_accuracy: 0.5191\n",
      "Epoch 21/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9576 - accuracy: 0.5515 - val_loss: 1.0076 - val_accuracy: 0.5154\n",
      "Epoch 22/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9534 - accuracy: 0.5586 - val_loss: 0.9998 - val_accuracy: 0.5340\n",
      "Epoch 23/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9352 - accuracy: 0.5789 - val_loss: 1.0027 - val_accuracy: 0.5200\n",
      "Epoch 24/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.9381 - accuracy: 0.5852 - val_loss: 0.9854 - val_accuracy: 0.5528\n",
      "Epoch 25/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9200 - accuracy: 0.6027 - val_loss: 0.9775 - val_accuracy: 0.5585\n",
      "Epoch 26/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9338 - accuracy: 0.5976 - val_loss: 0.9746 - val_accuracy: 0.5554\n",
      "Epoch 27/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9077 - accuracy: 0.6082 - val_loss: 0.9680 - val_accuracy: 0.5774\n",
      "Epoch 28/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.8897 - accuracy: 0.6281 - val_loss: 0.9529 - val_accuracy: 0.5808\n",
      "Epoch 29/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.8861 - accuracy: 0.6357 - val_loss: 0.9475 - val_accuracy: 0.6077\n",
      "Epoch 30/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.8762 - accuracy: 0.6480 - val_loss: 0.9319 - val_accuracy: 0.6085\n",
      "Epoch 31/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.8730 - accuracy: 0.6543 - val_loss: 0.9271 - val_accuracy: 0.6008\n",
      "Epoch 32/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.8582 - accuracy: 0.6673 - val_loss: 0.9157 - val_accuracy: 0.6108\n",
      "Epoch 33/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.8460 - accuracy: 0.6768 - val_loss: 0.9027 - val_accuracy: 0.6368\n",
      "Epoch 34/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.8307 - accuracy: 0.6899 - val_loss: 0.8893 - val_accuracy: 0.6511\n",
      "Epoch 35/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.8120 - accuracy: 0.7001 - val_loss: 0.8794 - val_accuracy: 0.6453\n",
      "Epoch 36/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.8052 - accuracy: 0.7038 - val_loss: 0.8702 - val_accuracy: 0.6476\n",
      "Epoch 37/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.7770 - accuracy: 0.7197 - val_loss: 0.8532 - val_accuracy: 0.6745\n",
      "Epoch 38/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.7763 - accuracy: 0.7261 - val_loss: 0.8448 - val_accuracy: 0.6796\n",
      "Epoch 39/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.7563 - accuracy: 0.7429 - val_loss: 0.8222 - val_accuracy: 0.6996\n",
      "Epoch 40/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.7339 - accuracy: 0.7618 - val_loss: 0.8104 - val_accuracy: 0.6930\n",
      "Epoch 41/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.7233 - accuracy: 0.7626 - val_loss: 0.7949 - val_accuracy: 0.7282\n",
      "Epoch 42/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.7037 - accuracy: 0.7767 - val_loss: 0.7869 - val_accuracy: 0.7164\n",
      "Epoch 43/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.7850 - val_loss: 0.7724 - val_accuracy: 0.7421\n",
      "Epoch 44/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.6675 - accuracy: 0.8006 - val_loss: 0.7502 - val_accuracy: 0.7530\n",
      "Epoch 45/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.6534 - accuracy: 0.8111 - val_loss: 0.7422 - val_accuracy: 0.7487\n",
      "Epoch 46/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.6403 - accuracy: 0.8191 - val_loss: 0.7203 - val_accuracy: 0.7658\n",
      "Epoch 47/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.6259 - accuracy: 0.8281 - val_loss: 0.7102 - val_accuracy: 0.7758\n",
      "Epoch 48/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.6093 - accuracy: 0.8367 - val_loss: 0.6916 - val_accuracy: 0.7864\n",
      "Epoch 49/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.5872 - accuracy: 0.8417 - val_loss: 0.6806 - val_accuracy: 0.7810\n",
      "Epoch 50/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.5688 - accuracy: 0.8532 - val_loss: 0.6647 - val_accuracy: 0.7981\n",
      "Epoch 51/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.5476 - accuracy: 0.8623 - val_loss: 0.6528 - val_accuracy: 0.8158\n",
      "Epoch 52/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.5353 - accuracy: 0.8687 - val_loss: 0.6305 - val_accuracy: 0.8147\n",
      "Epoch 53/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.5472 - accuracy: 0.8644 - val_loss: 0.6235 - val_accuracy: 0.8304\n",
      "Epoch 54/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.5177 - accuracy: 0.8788 - val_loss: 0.6072 - val_accuracy: 0.8201\n",
      "Epoch 55/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.4926 - accuracy: 0.8852 - val_loss: 0.5942 - val_accuracy: 0.8378\n",
      "Epoch 56/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.4857 - accuracy: 0.8889 - val_loss: 0.5821 - val_accuracy: 0.8332\n",
      "Epoch 57/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.4583 - accuracy: 0.8931 - val_loss: 0.5661 - val_accuracy: 0.8495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.4702 - accuracy: 0.8924 - val_loss: 0.5552 - val_accuracy: 0.8549\n",
      "Epoch 59/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.4329 - accuracy: 0.9042 - val_loss: 0.5444 - val_accuracy: 0.8538\n",
      "Epoch 60/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.4455 - accuracy: 0.8982 - val_loss: 0.5354 - val_accuracy: 0.8618\n",
      "Epoch 61/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.4476 - accuracy: 0.8995 - val_loss: 0.5229 - val_accuracy: 0.8601\n",
      "Epoch 62/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.4353 - accuracy: 0.8986 - val_loss: 0.5149 - val_accuracy: 0.8641\n",
      "Epoch 63/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.4122 - accuracy: 0.9048 - val_loss: 0.5016 - val_accuracy: 0.8721\n",
      "Epoch 64/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.3950 - accuracy: 0.9084 - val_loss: 0.4973 - val_accuracy: 0.8626\n",
      "Epoch 65/100\n",
      "438/438 [==============================] - 0s 993us/step - loss: 0.3966 - accuracy: 0.9087 - val_loss: 0.4830 - val_accuracy: 0.8704\n",
      "Epoch 66/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.3808 - accuracy: 0.9107 - val_loss: 0.4819 - val_accuracy: 0.8638\n",
      "Epoch 67/100\n",
      "438/438 [==============================] - 0s 911us/step - loss: 0.3719 - accuracy: 0.9118 - val_loss: 0.4717 - val_accuracy: 0.8695\n",
      "Epoch 68/100\n",
      "438/438 [==============================] - 0s 972us/step - loss: 0.3648 - accuracy: 0.9087 - val_loss: 0.4630 - val_accuracy: 0.8718\n",
      "Epoch 69/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.3568 - accuracy: 0.9147 - val_loss: 0.4598 - val_accuracy: 0.8761\n",
      "Epoch 70/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.3564 - accuracy: 0.9164 - val_loss: 0.4504 - val_accuracy: 0.8721\n",
      "Epoch 71/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.9138 - val_loss: 0.4430 - val_accuracy: 0.8801\n",
      "Epoch 72/100\n",
      "438/438 [==============================] - 0s 938us/step - loss: 0.3501 - accuracy: 0.9095 - val_loss: 0.4377 - val_accuracy: 0.8732\n",
      "Epoch 73/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.9168 - val_loss: 0.4285 - val_accuracy: 0.8764\n",
      "Epoch 74/100\n",
      "438/438 [==============================] - 0s 854us/step - loss: 0.3361 - accuracy: 0.9182 - val_loss: 0.4295 - val_accuracy: 0.8698\n",
      "Epoch 75/100\n",
      "438/438 [==============================] - 0s 911us/step - loss: 0.3303 - accuracy: 0.9156 - val_loss: 0.4214 - val_accuracy: 0.8775\n",
      "Epoch 76/100\n",
      "438/438 [==============================] - 0s 990us/step - loss: 0.3130 - accuracy: 0.9222 - val_loss: 0.4123 - val_accuracy: 0.8801\n",
      "Epoch 77/100\n",
      "438/438 [==============================] - 0s 899us/step - loss: 0.3060 - accuracy: 0.9242 - val_loss: 0.4067 - val_accuracy: 0.8798\n",
      "Epoch 78/100\n",
      "438/438 [==============================] - 0s 933us/step - loss: 0.3161 - accuracy: 0.9209 - val_loss: 0.4003 - val_accuracy: 0.8878\n",
      "Epoch 79/100\n",
      "438/438 [==============================] - 0s 856us/step - loss: 0.3045 - accuracy: 0.9200 - val_loss: 0.3966 - val_accuracy: 0.8846\n",
      "Epoch 80/100\n",
      "438/438 [==============================] - 0s 904us/step - loss: 0.2963 - accuracy: 0.9222 - val_loss: 0.3947 - val_accuracy: 0.8844\n",
      "Epoch 81/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.2895 - accuracy: 0.9257 - val_loss: 0.3912 - val_accuracy: 0.8872\n",
      "Epoch 82/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.2903 - accuracy: 0.9220 - val_loss: 0.3890 - val_accuracy: 0.8804\n",
      "Epoch 83/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2811 - accuracy: 0.9251 - val_loss: 0.3810 - val_accuracy: 0.8872\n",
      "Epoch 84/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2798 - accuracy: 0.9240 - val_loss: 0.3795 - val_accuracy: 0.8869\n",
      "Epoch 85/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2846 - accuracy: 0.9239 - val_loss: 0.3703 - val_accuracy: 0.8892\n",
      "Epoch 86/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.2703 - accuracy: 0.9259 - val_loss: 0.3720 - val_accuracy: 0.8869\n",
      "Epoch 87/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2615 - accuracy: 0.9274 - val_loss: 0.3646 - val_accuracy: 0.8912\n",
      "Epoch 88/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2767 - accuracy: 0.9272 - val_loss: 0.3659 - val_accuracy: 0.8855\n",
      "Epoch 89/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.2630 - accuracy: 0.9290 - val_loss: 0.3605 - val_accuracy: 0.8886\n",
      "Epoch 90/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2612 - accuracy: 0.9304 - val_loss: 0.3645 - val_accuracy: 0.8866\n",
      "Epoch 91/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2536 - accuracy: 0.9315 - val_loss: 0.3541 - val_accuracy: 0.8903\n",
      "Epoch 92/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2436 - accuracy: 0.9343 - val_loss: 0.3564 - val_accuracy: 0.8869\n",
      "Epoch 93/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2446 - accuracy: 0.9311 - val_loss: 0.3543 - val_accuracy: 0.8866\n",
      "Epoch 94/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2484 - accuracy: 0.9341 - val_loss: 0.3446 - val_accuracy: 0.8955\n",
      "Epoch 95/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.9349 - val_loss: 0.3521 - val_accuracy: 0.8864\n",
      "Epoch 96/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2333 - accuracy: 0.9359 - val_loss: 0.3469 - val_accuracy: 0.8892\n",
      "Epoch 97/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2297 - accuracy: 0.9378 - val_loss: 0.3476 - val_accuracy: 0.8918\n",
      "Epoch 98/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2275 - accuracy: 0.9361 - val_loss: 0.3406 - val_accuracy: 0.8943\n",
      "Epoch 99/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2308 - accuracy: 0.9373 - val_loss: 0.3353 - val_accuracy: 0.8946\n",
      "Epoch 100/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2208 - accuracy: 0.9396 - val_loss: 0.3545 - val_accuracy: 0.8792\n",
      "Neural Net 1 time: 59.71 s\n"
     ]
    }
   ],
   "source": [
    "## Training the model \n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "nn_mod_1.fit(X_train_encoded,\n",
    "           y_train_encoded,\n",
    "           epochs=100,\n",
    "           validation_split=0.2)\n",
    "\n",
    "toc = time.time()\n",
    "print('Neural Net 1 time:', round(toc-tic, 2),'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 0s 997us/step - loss: 0.3434 - accuracy: 0.8982\n",
      "0.8981740474700928\n"
     ]
    }
   ],
   "source": [
    "## Evaluating the model\n",
    "loss, acc = nn_mod_1.evaluate(X_test_encoded, y_test_encoded)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Hidden Layer Model ReLU\n",
    "\n",
    "Switching sigmoid to ReLU max(0,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 1.2545 - accuracy: 0.4556 - val_loss: 1.0271 - val_accuracy: 0.4874\n",
      "Epoch 2/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9934 - accuracy: 0.5143 - val_loss: 1.0242 - val_accuracy: 0.5143\n",
      "Epoch 3/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9721 - accuracy: 0.5506 - val_loss: 1.0067 - val_accuracy: 0.5286\n",
      "Epoch 4/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9317 - accuracy: 0.5911 - val_loss: 0.9872 - val_accuracy: 0.5702\n",
      "Epoch 5/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.9149 - accuracy: 0.6360 - val_loss: 0.9625 - val_accuracy: 0.6022\n",
      "Epoch 6/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.8614 - accuracy: 0.6865 - val_loss: 0.9295 - val_accuracy: 0.6371\n",
      "Epoch 7/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.8180 - accuracy: 0.7260 - val_loss: 0.8995 - val_accuracy: 0.6779\n",
      "Epoch 8/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.7872 - accuracy: 0.7505 - val_loss: 0.8639 - val_accuracy: 0.7125\n",
      "Epoch 9/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.7343 - accuracy: 0.7815 - val_loss: 0.8309 - val_accuracy: 0.7364\n",
      "Epoch 10/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.6954 - accuracy: 0.8082 - val_loss: 0.7974 - val_accuracy: 0.7590\n",
      "Epoch 11/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.6407 - accuracy: 0.8247 - val_loss: 0.7649 - val_accuracy: 0.7653\n",
      "Epoch 12/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.5900 - accuracy: 0.8444 - val_loss: 0.7269 - val_accuracy: 0.7704\n",
      "Epoch 13/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.5609 - accuracy: 0.8645 - val_loss: 0.6987 - val_accuracy: 0.7913\n",
      "Epoch 14/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.5220 - accuracy: 0.8723 - val_loss: 0.6751 - val_accuracy: 0.8158\n",
      "Epoch 15/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.8831 - val_loss: 0.6445 - val_accuracy: 0.8218\n",
      "Epoch 16/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.4716 - accuracy: 0.8877 - val_loss: 0.6245 - val_accuracy: 0.8292\n",
      "Epoch 17/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.4551 - accuracy: 0.8954 - val_loss: 0.6018 - val_accuracy: 0.8424\n",
      "Epoch 18/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.4375 - accuracy: 0.9007 - val_loss: 0.5872 - val_accuracy: 0.8409\n",
      "Epoch 19/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.4251 - accuracy: 0.9006 - val_loss: 0.5682 - val_accuracy: 0.8518\n",
      "Epoch 20/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.9111 - val_loss: 0.5490 - val_accuracy: 0.8527\n",
      "Epoch 21/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.3722 - accuracy: 0.9106 - val_loss: 0.5333 - val_accuracy: 0.8569\n",
      "Epoch 22/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.3570 - accuracy: 0.9122 - val_loss: 0.5264 - val_accuracy: 0.8615\n",
      "Epoch 23/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.9185 - val_loss: 0.5184 - val_accuracy: 0.8664\n",
      "Epoch 24/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.3232 - accuracy: 0.9193 - val_loss: 0.5037 - val_accuracy: 0.8624\n",
      "Epoch 25/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.3034 - accuracy: 0.9242 - val_loss: 0.4878 - val_accuracy: 0.8692\n",
      "Epoch 26/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.3090 - accuracy: 0.9235 - val_loss: 0.4833 - val_accuracy: 0.8686\n",
      "Epoch 27/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2756 - accuracy: 0.9289 - val_loss: 0.4826 - val_accuracy: 0.8775\n",
      "Epoch 28/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.2685 - accuracy: 0.9322 - val_loss: 0.4559 - val_accuracy: 0.8755\n",
      "Epoch 29/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.2630 - accuracy: 0.9342 - val_loss: 0.4520 - val_accuracy: 0.8798\n",
      "Epoch 30/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.2514 - accuracy: 0.9357 - val_loss: 0.4418 - val_accuracy: 0.8821\n",
      "Epoch 31/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2459 - accuracy: 0.9362 - val_loss: 0.4311 - val_accuracy: 0.8869\n",
      "Epoch 32/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.2333 - accuracy: 0.9411 - val_loss: 0.4268 - val_accuracy: 0.8866\n",
      "Epoch 33/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.2294 - accuracy: 0.9414 - val_loss: 0.4260 - val_accuracy: 0.8906\n",
      "Epoch 34/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.2232 - accuracy: 0.9423 - val_loss: 0.4268 - val_accuracy: 0.8878\n",
      "Epoch 35/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2153 - accuracy: 0.9451 - val_loss: 0.4078 - val_accuracy: 0.8918\n",
      "Epoch 36/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.2087 - accuracy: 0.9504 - val_loss: 0.4079 - val_accuracy: 0.8886\n",
      "Epoch 37/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1883 - accuracy: 0.9556 - val_loss: 0.4041 - val_accuracy: 0.8961\n",
      "Epoch 38/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.1933 - accuracy: 0.9534 - val_loss: 0.4109 - val_accuracy: 0.8932\n",
      "Epoch 39/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.2040 - accuracy: 0.9532 - val_loss: 0.3865 - val_accuracy: 0.8983\n",
      "Epoch 40/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.9573 - val_loss: 0.3836 - val_accuracy: 0.9009\n",
      "Epoch 41/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.9586 - val_loss: 0.3789 - val_accuracy: 0.9041\n",
      "Epoch 42/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1685 - accuracy: 0.9614 - val_loss: 0.3860 - val_accuracy: 0.8981\n",
      "Epoch 43/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1696 - accuracy: 0.9604 - val_loss: 0.3951 - val_accuracy: 0.9061\n",
      "Epoch 44/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.9630 - val_loss: 0.3722 - val_accuracy: 0.9049\n",
      "Epoch 45/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1593 - accuracy: 0.9642 - val_loss: 0.3692 - val_accuracy: 0.9066\n",
      "Epoch 46/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.1621 - accuracy: 0.9666 - val_loss: 0.3657 - val_accuracy: 0.9052\n",
      "Epoch 47/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.1552 - accuracy: 0.9655 - val_loss: 0.3723 - val_accuracy: 0.9058\n",
      "Epoch 48/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1531 - accuracy: 0.9650 - val_loss: 0.3810 - val_accuracy: 0.9049\n",
      "Epoch 49/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1387 - accuracy: 0.9698 - val_loss: 0.3690 - val_accuracy: 0.9049\n",
      "Epoch 50/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.1372 - accuracy: 0.9702 - val_loss: 0.3755 - val_accuracy: 0.9072\n",
      "Epoch 51/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.9706 - val_loss: 0.3658 - val_accuracy: 0.9095\n",
      "Epoch 52/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.9710 - val_loss: 0.3625 - val_accuracy: 0.9092\n",
      "Epoch 53/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.9703 - val_loss: 0.3663 - val_accuracy: 0.9109\n",
      "Epoch 54/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.1399 - accuracy: 0.9733 - val_loss: 0.3706 - val_accuracy: 0.9063\n",
      "Epoch 55/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.9744 - val_loss: 0.3684 - val_accuracy: 0.9092\n",
      "Epoch 56/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.9743 - val_loss: 0.3636 - val_accuracy: 0.9083\n",
      "Epoch 57/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1180 - accuracy: 0.9767 - val_loss: 0.3588 - val_accuracy: 0.9066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9739 - val_loss: 0.3697 - val_accuracy: 0.9098\n",
      "Epoch 59/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1022 - accuracy: 0.9773 - val_loss: 0.3728 - val_accuracy: 0.9075\n",
      "Epoch 60/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1247 - accuracy: 0.9752 - val_loss: 0.3723 - val_accuracy: 0.9143\n",
      "Epoch 61/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1283 - accuracy: 0.9759 - val_loss: 0.3713 - val_accuracy: 0.9081\n",
      "Epoch 62/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1304 - accuracy: 0.9767 - val_loss: 0.3881 - val_accuracy: 0.9098\n",
      "Epoch 63/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.1144 - accuracy: 0.9764 - val_loss: 0.3779 - val_accuracy: 0.9095\n",
      "Epoch 64/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1033 - accuracy: 0.9804 - val_loss: 0.3756 - val_accuracy: 0.9083\n",
      "Epoch 65/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.9776 - val_loss: 0.3676 - val_accuracy: 0.9095\n",
      "Epoch 66/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9789 - val_loss: 0.3803 - val_accuracy: 0.9101\n",
      "Epoch 67/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1041 - accuracy: 0.9801 - val_loss: 0.3750 - val_accuracy: 0.9149\n",
      "Epoch 68/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1039 - accuracy: 0.9801 - val_loss: 0.3807 - val_accuracy: 0.9143\n",
      "Epoch 69/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.1064 - accuracy: 0.9804 - val_loss: 0.3745 - val_accuracy: 0.9146\n",
      "Epoch 70/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.1134 - accuracy: 0.9812 - val_loss: 0.3865 - val_accuracy: 0.9155\n",
      "Epoch 71/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.0963 - accuracy: 0.9830 - val_loss: 0.3816 - val_accuracy: 0.9129\n",
      "Epoch 72/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1075 - accuracy: 0.9813 - val_loss: 0.3777 - val_accuracy: 0.9098\n",
      "Epoch 73/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9828 - val_loss: 0.3825 - val_accuracy: 0.9178\n",
      "Epoch 74/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1030 - accuracy: 0.9820 - val_loss: 0.3907 - val_accuracy: 0.9095\n",
      "Epoch 75/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.1085 - accuracy: 0.9811 - val_loss: 0.3835 - val_accuracy: 0.9149\n",
      "Epoch 76/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.1005 - accuracy: 0.9823 - val_loss: 0.3951 - val_accuracy: 0.9152\n",
      "Epoch 77/100\n",
      "438/438 [==============================] - 0s 1ms/step - loss: 0.1022 - accuracy: 0.9826 - val_loss: 0.3812 - val_accuracy: 0.9086\n",
      "Epoch 78/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.1125 - accuracy: 0.9820 - val_loss: 0.3879 - val_accuracy: 0.9118\n",
      "Epoch 79/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.0900 - accuracy: 0.9839 - val_loss: 0.3953 - val_accuracy: 0.9138\n",
      "Epoch 80/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.0957 - accuracy: 0.9821 - val_loss: 0.4047 - val_accuracy: 0.9086\n",
      "Epoch 81/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.1014 - accuracy: 0.9842 - val_loss: 0.4005 - val_accuracy: 0.9098\n",
      "Epoch 82/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.0980 - accuracy: 0.9836 - val_loss: 0.4064 - val_accuracy: 0.9195\n",
      "Epoch 83/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.0919 - accuracy: 0.9843 - val_loss: 0.4003 - val_accuracy: 0.9140\n",
      "Epoch 84/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.0844 - accuracy: 0.9854 - val_loss: 0.4027 - val_accuracy: 0.9146\n",
      "Epoch 85/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.0972 - accuracy: 0.9848 - val_loss: 0.3998 - val_accuracy: 0.9158\n",
      "Epoch 86/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.0811 - accuracy: 0.9862 - val_loss: 0.4103 - val_accuracy: 0.9118\n",
      "Epoch 87/100\n",
      "438/438 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.98 - 1s 1ms/step - loss: 0.0809 - accuracy: 0.9860 - val_loss: 0.4103 - val_accuracy: 0.9118\n",
      "Epoch 88/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.0988 - accuracy: 0.9863 - val_loss: 0.4128 - val_accuracy: 0.9123\n",
      "Epoch 89/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.0952 - accuracy: 0.9868 - val_loss: 0.4153 - val_accuracy: 0.9146\n",
      "Epoch 90/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.0929 - accuracy: 0.9866 - val_loss: 0.4385 - val_accuracy: 0.9129\n",
      "Epoch 91/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.0897 - accuracy: 0.9848 - val_loss: 0.4296 - val_accuracy: 0.9109\n",
      "Epoch 92/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0746 - accuracy: 0.9882 - val_loss: 0.4330 - val_accuracy: 0.9089\n",
      "Epoch 93/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0829 - accuracy: 0.9882 - val_loss: 0.4387 - val_accuracy: 0.9121\n",
      "Epoch 94/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9879 - val_loss: 0.4282 - val_accuracy: 0.9121\n",
      "Epoch 95/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9887 - val_loss: 0.4345 - val_accuracy: 0.9149\n",
      "Epoch 96/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0755 - accuracy: 0.9899 - val_loss: 0.4478 - val_accuracy: 0.9118\n",
      "Epoch 97/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0768 - accuracy: 0.9891 - val_loss: 0.4520 - val_accuracy: 0.9146\n",
      "Epoch 98/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0792 - accuracy: 0.9898 - val_loss: 0.4430 - val_accuracy: 0.9095\n",
      "Epoch 99/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0773 - accuracy: 0.9899 - val_loss: 0.4480 - val_accuracy: 0.9058\n",
      "Epoch 100/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0766 - accuracy: 0.9908 - val_loss: 0.4579 - val_accuracy: 0.9155\n",
      "Neural Net 1 time: 56.86 s\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.9232\n",
      "0.9232307076454163\n"
     ]
    }
   ],
   "source": [
    "nn_mod_2 = Sequential()\n",
    "nn_mod_2.add(Input(shape=(75,)))\n",
    "nn_mod_2.add(Dense(100, activation='relu'))\n",
    "nn_mod_2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "opt = RMSprop()\n",
    "nn_mod_2.compile(optimizer=opt,\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "nn_mod_2.fit(X_train_encoded,\n",
    "           y_train_encoded,\n",
    "           epochs=100,\n",
    "           validation_split=0.2)\n",
    "\n",
    "toc = time.time()\n",
    "print('Neural Net 1 time:', round(toc-tic, 2),'s')\n",
    "\n",
    "loss, acc = nn_mod_2.evaluate(X_test_encoded, y_test_encoded)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it better than sigmoid?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three Hidden Layer Model ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "438/438 [==============================] - 2s 3ms/step - loss: 1.2330 - accuracy: 0.4754 - val_loss: 1.0223 - val_accuracy: 0.4826\n",
      "Epoch 2/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.9862 - accuracy: 0.5238 - val_loss: 1.0184 - val_accuracy: 0.5066\n",
      "Epoch 3/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.9514 - accuracy: 0.5647 - val_loss: 0.9748 - val_accuracy: 0.5640\n",
      "Epoch 4/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.8795 - accuracy: 0.6162 - val_loss: 0.9267 - val_accuracy: 0.5934\n",
      "Epoch 5/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.8214 - accuracy: 0.6605 - val_loss: 0.8818 - val_accuracy: 0.6191\n",
      "Epoch 6/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.7176 - accuracy: 0.7128 - val_loss: 0.8041 - val_accuracy: 0.6605\n",
      "Epoch 7/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.6335 - accuracy: 0.7601 - val_loss: 0.7261 - val_accuracy: 0.7119\n",
      "Epoch 8/100\n",
      "438/438 [==============================] - 1s 3ms/step - loss: 0.5568 - accuracy: 0.7921 - val_loss: 0.6456 - val_accuracy: 0.7362\n",
      "Epoch 9/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.4714 - accuracy: 0.8301 - val_loss: 0.5563 - val_accuracy: 0.7864\n",
      "Epoch 10/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.3903 - accuracy: 0.8694 - val_loss: 0.5634 - val_accuracy: 0.7750\n",
      "Epoch 11/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.3366 - accuracy: 0.8901 - val_loss: 0.4566 - val_accuracy: 0.8310\n",
      "Epoch 12/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2834 - accuracy: 0.9115 - val_loss: 0.4594 - val_accuracy: 0.8275\n",
      "Epoch 13/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2662 - accuracy: 0.9201 - val_loss: 0.4244 - val_accuracy: 0.8552\n",
      "Epoch 14/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2441 - accuracy: 0.9220 - val_loss: 0.4200 - val_accuracy: 0.8532\n",
      "Epoch 15/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2371 - accuracy: 0.9290 - val_loss: 0.4347 - val_accuracy: 0.8558\n",
      "Epoch 16/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.2130 - accuracy: 0.9378 - val_loss: 0.4427 - val_accuracy: 0.8372\n",
      "Epoch 17/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1970 - accuracy: 0.9444 - val_loss: 0.4236 - val_accuracy: 0.8612\n",
      "Epoch 18/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1887 - accuracy: 0.9453 - val_loss: 0.4269 - val_accuracy: 0.8512\n",
      "Epoch 19/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.9491 - val_loss: 0.4606 - val_accuracy: 0.8607\n",
      "Epoch 20/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1537 - accuracy: 0.9584 - val_loss: 0.3983 - val_accuracy: 0.8624\n",
      "Epoch 21/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1469 - accuracy: 0.9558 - val_loss: 0.4400 - val_accuracy: 0.8641\n",
      "Epoch 22/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1470 - accuracy: 0.9558 - val_loss: 0.4228 - val_accuracy: 0.8726\n",
      "Epoch 23/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1294 - accuracy: 0.9593 - val_loss: 0.4597 - val_accuracy: 0.8601\n",
      "Epoch 24/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1281 - accuracy: 0.9627 - val_loss: 0.4491 - val_accuracy: 0.8515\n",
      "Epoch 25/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1173 - accuracy: 0.9651 - val_loss: 0.5260 - val_accuracy: 0.8547\n",
      "Epoch 26/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.1212 - accuracy: 0.9656 - val_loss: 0.5818 - val_accuracy: 0.8584\n",
      "Epoch 27/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.1011 - accuracy: 0.9709 - val_loss: 0.4684 - val_accuracy: 0.8669\n",
      "Epoch 28/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9726 - val_loss: 0.4617 - val_accuracy: 0.8735\n",
      "Epoch 29/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9720 - val_loss: 0.7972 - val_accuracy: 0.7713\n",
      "Epoch 30/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9717 - val_loss: 0.4783 - val_accuracy: 0.8544\n",
      "Epoch 31/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9742 - val_loss: 0.6121 - val_accuracy: 0.8621\n",
      "Epoch 32/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0884 - accuracy: 0.9746 - val_loss: 0.5211 - val_accuracy: 0.8704\n",
      "Epoch 33/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0832 - accuracy: 0.9743 - val_loss: 0.5144 - val_accuracy: 0.8592\n",
      "Epoch 34/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.9758 - val_loss: 0.5289 - val_accuracy: 0.8635\n",
      "Epoch 35/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0767 - accuracy: 0.9767 - val_loss: 0.5587 - val_accuracy: 0.8635\n",
      "Epoch 36/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0709 - accuracy: 0.9801 - val_loss: 0.5514 - val_accuracy: 0.8684\n",
      "Epoch 37/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0718 - accuracy: 0.9799 - val_loss: 0.5298 - val_accuracy: 0.8598\n",
      "Epoch 38/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0667 - accuracy: 0.9791 - val_loss: 0.5516 - val_accuracy: 0.8692\n",
      "Epoch 39/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0681 - accuracy: 0.9829 - val_loss: 0.6646 - val_accuracy: 0.8646\n",
      "Epoch 40/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0600 - accuracy: 0.9836 - val_loss: 0.5543 - val_accuracy: 0.8735\n",
      "Epoch 41/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.9834 - val_loss: 0.5349 - val_accuracy: 0.8666\n",
      "Epoch 42/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0525 - accuracy: 0.9850 - val_loss: 0.6001 - val_accuracy: 0.8646\n",
      "Epoch 43/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0584 - accuracy: 0.9826 - val_loss: 0.6087 - val_accuracy: 0.8467\n",
      "Epoch 44/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0504 - accuracy: 0.9851 - val_loss: 0.5588 - val_accuracy: 0.8724\n",
      "Epoch 45/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0473 - accuracy: 0.9875 - val_loss: 0.6632 - val_accuracy: 0.8692\n",
      "Epoch 46/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0462 - accuracy: 0.9874 - val_loss: 0.7400 - val_accuracy: 0.8250\n",
      "Epoch 47/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0475 - accuracy: 0.9880 - val_loss: 0.6733 - val_accuracy: 0.8452\n",
      "Epoch 48/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0496 - accuracy: 0.9871 - val_loss: 0.6489 - val_accuracy: 0.8644\n",
      "Epoch 49/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0495 - accuracy: 0.9857 - val_loss: 0.7218 - val_accuracy: 0.8724\n",
      "Epoch 50/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0371 - accuracy: 0.9891 - val_loss: 0.6610 - val_accuracy: 0.8732\n",
      "Epoch 51/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0399 - accuracy: 0.9879 - val_loss: 0.6545 - val_accuracy: 0.8704\n",
      "Epoch 52/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0365 - accuracy: 0.9897 - val_loss: 0.6668 - val_accuracy: 0.8601\n",
      "Epoch 53/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0463 - accuracy: 0.9861 - val_loss: 1.0747 - val_accuracy: 0.8492\n",
      "Epoch 54/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0427 - accuracy: 0.9897 - val_loss: 0.6843 - val_accuracy: 0.8738\n",
      "Epoch 55/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0356 - accuracy: 0.9892 - val_loss: 0.8437 - val_accuracy: 0.8675\n",
      "Epoch 56/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0378 - accuracy: 0.9897 - val_loss: 0.8098 - val_accuracy: 0.8661\n",
      "Epoch 57/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0321 - accuracy: 0.9903 - val_loss: 0.8019 - val_accuracy: 0.8364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0362 - accuracy: 0.9910 - val_loss: 0.7031 - val_accuracy: 0.8584\n",
      "Epoch 59/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0303 - accuracy: 0.9899 - val_loss: 0.7659 - val_accuracy: 0.8715\n",
      "Epoch 60/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0329 - accuracy: 0.9907 - val_loss: 0.7539 - val_accuracy: 0.8778\n",
      "Epoch 61/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0452 - accuracy: 0.9871 - val_loss: 0.7499 - val_accuracy: 0.8561\n",
      "Epoch 62/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0386 - accuracy: 0.9899 - val_loss: 0.8242 - val_accuracy: 0.8772\n",
      "Epoch 63/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0320 - accuracy: 0.9910 - val_loss: 0.7530 - val_accuracy: 0.8575\n",
      "Epoch 64/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 0.9444 - val_accuracy: 0.8601\n",
      "Epoch 65/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0311 - accuracy: 0.9923 - val_loss: 0.8151 - val_accuracy: 0.8741\n",
      "Epoch 66/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0281 - accuracy: 0.9912 - val_loss: 0.8055 - val_accuracy: 0.8684\n",
      "Epoch 67/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0291 - accuracy: 0.9913 - val_loss: 0.7903 - val_accuracy: 0.8681\n",
      "Epoch 68/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0314 - accuracy: 0.9912 - val_loss: 0.7914 - val_accuracy: 0.8712\n",
      "Epoch 69/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0268 - accuracy: 0.9910 - val_loss: 0.8029 - val_accuracy: 0.8741\n",
      "Epoch 70/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0304 - accuracy: 0.9912 - val_loss: 0.8109 - val_accuracy: 0.8781\n",
      "Epoch 71/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0254 - accuracy: 0.9911 - val_loss: 0.7857 - val_accuracy: 0.8712\n",
      "Epoch 72/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0271 - accuracy: 0.9921 - val_loss: 0.9225 - val_accuracy: 0.8312\n",
      "Epoch 73/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0273 - accuracy: 0.9918 - val_loss: 0.9724 - val_accuracy: 0.8655\n",
      "Epoch 74/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0319 - accuracy: 0.9910 - val_loss: 0.8665 - val_accuracy: 0.8658\n",
      "Epoch 75/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0288 - accuracy: 0.9932 - val_loss: 0.9314 - val_accuracy: 0.8778\n",
      "Epoch 76/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0276 - accuracy: 0.9922 - val_loss: 0.9014 - val_accuracy: 0.8735\n",
      "Epoch 77/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0242 - accuracy: 0.9929 - val_loss: 0.9094 - val_accuracy: 0.8709\n",
      "Epoch 78/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0315 - accuracy: 0.9923 - val_loss: 0.8232 - val_accuracy: 0.8669\n",
      "Epoch 79/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.0248 - accuracy: 0.9931 - val_loss: 0.8518 - val_accuracy: 0.8629\n",
      "Epoch 80/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.9642 - val_accuracy: 0.8404\n",
      "Epoch 81/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9945 - val_loss: 0.8721 - val_accuracy: 0.8749\n",
      "Epoch 82/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0194 - accuracy: 0.9953 - val_loss: 0.9020 - val_accuracy: 0.8721\n",
      "Epoch 83/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.0225 - accuracy: 0.9936 - val_loss: 0.9255 - val_accuracy: 0.8846\n",
      "Epoch 84/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0182 - accuracy: 0.9955 - val_loss: 1.0146 - val_accuracy: 0.8764\n",
      "Epoch 85/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9940 - val_loss: 1.0106 - val_accuracy: 0.8778\n",
      "Epoch 86/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9942 - val_loss: 0.9621 - val_accuracy: 0.8772\n",
      "Epoch 87/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.9149 - val_accuracy: 0.8521\n",
      "Epoch 88/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.0193 - accuracy: 0.9946 - val_loss: 1.0291 - val_accuracy: 0.8729\n",
      "Epoch 89/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0165 - accuracy: 0.9958 - val_loss: 1.0059 - val_accuracy: 0.8781\n",
      "Epoch 90/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0179 - accuracy: 0.9961 - val_loss: 1.0557 - val_accuracy: 0.8738\n",
      "Epoch 91/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0136 - accuracy: 0.9965 - val_loss: 0.9462 - val_accuracy: 0.8778\n",
      "Epoch 92/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0160 - accuracy: 0.9955 - val_loss: 0.9993 - val_accuracy: 0.8746\n",
      "Epoch 93/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0122 - accuracy: 0.9967 - val_loss: 1.1345 - val_accuracy: 0.8706\n",
      "Epoch 94/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 1.0063 - val_accuracy: 0.8729\n",
      "Epoch 95/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0169 - accuracy: 0.9956 - val_loss: 1.0724 - val_accuracy: 0.8527\n",
      "Epoch 96/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.0135 - accuracy: 0.9950 - val_loss: 0.9294 - val_accuracy: 0.8744\n",
      "Epoch 97/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 0.9723 - val_accuracy: 0.8769\n",
      "Epoch 98/100\n",
      "438/438 [==============================] - 1s 2ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 1.0497 - val_accuracy: 0.8629\n",
      "Epoch 99/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.0162 - accuracy: 0.9960 - val_loss: 1.0245 - val_accuracy: 0.8549\n",
      "Epoch 100/100\n",
      "438/438 [==============================] - 1s 1ms/step - loss: 0.0140 - accuracy: 0.9962 - val_loss: 1.5944 - val_accuracy: 0.8504\n",
      "Neural Net 1 time: 78.32 s\n",
      "235/235 [==============================] - 0s 720us/step - loss: 1.5694 - accuracy: 0.8699\n",
      "0.869918704032898\n"
     ]
    }
   ],
   "source": [
    "nn_mod_3 = Sequential()\n",
    "nn_mod_3.add(Input(shape=(75,)))\n",
    "nn_mod_3.add(Dense(75, activation='relu'))\n",
    "nn_mod_3.add(Dense(50, activation='relu'))\n",
    "nn_mod_3.add(Dense(25, activation='relu'))\n",
    "nn_mod_3.add(Dense(10, activation='softmax'))\n",
    "\n",
    "opt = RMSprop()\n",
    "nn_mod_3.compile(optimizer=opt,\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "nn_mod_3.fit(X_train_encoded,\n",
    "           y_train_encoded,\n",
    "           epochs=100,\n",
    "           validation_split=0.2)\n",
    "\n",
    "toc = time.time()\n",
    "print('Neural Net 1 time:', round(toc-tic, 2),'s')\n",
    "\n",
    "loss, acc = nn_mod_3.evaluate(X_test_encoded, y_test_encoded)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6057 entries, 0 to 6056\n",
      "Data columns (total 11 columns):\n",
      "CTR              6057 non-null float64\n",
      "titleWords       6057 non-null int64\n",
      "adWords          6057 non-null int64\n",
      "depth            6057 non-null int64\n",
      "position         6057 non-null int64\n",
      "advCTR           6057 non-null float64\n",
      "advCTRInPos      6057 non-null float64\n",
      "queryCTR         6057 non-null float64\n",
      "queryCTRInPos    6057 non-null float64\n",
      "gender           6057 non-null object\n",
      "age              6057 non-null object\n",
      "dtypes: float64(5), int64(4), object(2)\n",
      "memory usage: 520.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CTR</th>\n",
       "      <th>titleWords</th>\n",
       "      <th>adWords</th>\n",
       "      <th>depth</th>\n",
       "      <th>position</th>\n",
       "      <th>advCTR</th>\n",
       "      <th>advCTRInPos</th>\n",
       "      <th>queryCTR</th>\n",
       "      <th>queryCTRInPos</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>male</td>\n",
       "      <td>0-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>male</td>\n",
       "      <td>25-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0825</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>female</td>\n",
       "      <td>13-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>female</td>\n",
       "      <td>25-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>female</td>\n",
       "      <td>0-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CTR  titleWords  adWords  depth  position  advCTR  advCTRInPos  \\\n",
       "0  0.0000           8       17      1         1  0.0136       0.0153   \n",
       "1  0.0000           9       19      3         3  0.0199       0.0088   \n",
       "2  0.0675           6       30      2         1  0.0825       0.1002   \n",
       "3  0.0000           5       19      3         2  0.0116       0.0090   \n",
       "4  0.0000          10       22      1         1  0.0186       0.0284   \n",
       "\n",
       "   queryCTR  queryCTRInPos  gender    age  \n",
       "0    0.0000         0.0000    male   0-12  \n",
       "1    0.0394         0.0125    male  25-30  \n",
       "2    0.0200         0.0256  female  13-18  \n",
       "3    0.0042         0.0017  female  25-30  \n",
       "4    0.0294         0.0431  female   0-12  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctr = pd.read_csv('CTR.csv')\n",
    "\n",
    "ctr.info()\n",
    "ctr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CTR</th>\n",
       "      <th>titleWords</th>\n",
       "      <th>adWords</th>\n",
       "      <th>depth</th>\n",
       "      <th>position</th>\n",
       "      <th>advCTR</th>\n",
       "      <th>advCTRInPos</th>\n",
       "      <th>queryCTR</th>\n",
       "      <th>queryCTRInPos</th>\n",
       "      <th>age_13-18</th>\n",
       "      <th>age_19-24</th>\n",
       "      <th>age_25-30</th>\n",
       "      <th>age_31-40</th>\n",
       "      <th>age_41+</th>\n",
       "      <th>age_unknown</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>gender_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0825</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6052</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0273</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6053</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>0.0982</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6054</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0496</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0467</td>\n",
       "      <td>0.0668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6055</td>\n",
       "      <td>0.1339</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0566</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6056</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.0486</td>\n",
       "      <td>0.0683</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6057 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CTR  titleWords  adWords  depth  position  advCTR  advCTRInPos  \\\n",
       "0     0.0000           8       17      1         1  0.0136       0.0153   \n",
       "1     0.0000           9       19      3         3  0.0199       0.0088   \n",
       "2     0.0675           6       30      2         1  0.0825       0.1002   \n",
       "3     0.0000           5       19      3         2  0.0116       0.0090   \n",
       "4     0.0000          10       22      1         1  0.0186       0.0284   \n",
       "...      ...         ...      ...    ...       ...     ...          ...   \n",
       "6052  0.0182           8       16      1         1  0.0273       0.0356   \n",
       "6053  0.0475           6       20      1         1  0.0919       0.0982   \n",
       "6054  0.0141           9       26      3         1  0.0496       0.0523   \n",
       "6055  0.1339           9       16      2         1  0.0566       0.0610   \n",
       "6056  0.0137          11       23      1         1  0.0402       0.0486   \n",
       "\n",
       "      queryCTR  queryCTRInPos  age_13-18  age_19-24  age_25-30  age_31-40  \\\n",
       "0       0.0000         0.0000          0          0          0          0   \n",
       "1       0.0394         0.0125          0          0          1          0   \n",
       "2       0.0200         0.0256          1          0          0          0   \n",
       "3       0.0042         0.0017          0          0          1          0   \n",
       "4       0.0294         0.0431          0          0          0          0   \n",
       "...        ...            ...        ...        ...        ...        ...   \n",
       "6052    0.0040         0.0000          0          0          0          0   \n",
       "6053    0.0000         0.0000          0          0          0          0   \n",
       "6054    0.0467         0.0668          0          0          0          0   \n",
       "6055    0.0618         0.1012          0          0          0          0   \n",
       "6056    0.0683         0.0979          0          0          0          0   \n",
       "\n",
       "      age_41+  age_unknown  gender_male  gender_unknown  \n",
       "0           0            0            1               0  \n",
       "1           0            0            1               0  \n",
       "2           0            0            0               0  \n",
       "3           0            0            0               0  \n",
       "4           0            0            0               0  \n",
       "...       ...          ...          ...             ...  \n",
       "6052        0            1            0               1  \n",
       "6053        0            1            0               1  \n",
       "6054        0            1            0               1  \n",
       "6055        0            1            0               1  \n",
       "6056        0            1            0               1  \n",
       "\n",
       "[6057 rows x 17 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctr[['age','gender']] = ctr[['age','gender']].astype('category')\n",
    "ctr_encoded = pd.get_dummies(ctr, columns = ['age','gender'],drop_first = True)\n",
    "ctr_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OSR2(y_pred, y_test, y_train):\n",
    "    \n",
    "    SSE = np.sum((y_test - y_pred)**2)\n",
    "    SST = np.sum((y_test - np.mean(y_train))**2)\n",
    "                 \n",
    "    return (1 - SSE/SST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6057, 17)\n",
      "(4240, 17)\n",
      "(1817, 17)\n"
     ]
    }
   ],
   "source": [
    "train_ctr_encoded = ctr_encoded.sample(frac=0.7, random_state=88)\n",
    "test_ctr_encoded = ctr_encoded.drop(train_ctr_encoded.index)\n",
    "\n",
    "print(ctr_encoded.shape)\n",
    "print(train_ctr_encoded.shape)\n",
    "print(test_ctr_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ctr = train_ctr_encoded['CTR']\n",
    "X_train_ctr_encoded = train_ctr_encoded.drop(columns = ['CTR'])\n",
    "\n",
    "y_test_ctr = test_ctr_encoded['CTR']\n",
    "X_test_ctr_encoded = test_ctr_encoded.drop(columns = ['CTR'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep for Keras\n",
    "#trainX <- model.matrix(CTR ~ . , data = train.ctr)\n",
    "#trainX <- trainX[,2:17]\n",
    "#trainY <- train.ctr$CTR\n",
    "\n",
    "#testX <- model.matrix(CTR ~ . , data = test.ctr)\n",
    "#testX <- testX[,2:17]\n",
    "#testY <- test.ctr$CTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "106/106 [==============================] - 1s 3ms/step - loss: 2.0963 - mean_squared_error: 2.0963 - val_loss: 0.4616 - val_mean_squared_error: 0.4616\n",
      "Epoch 2/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1975 - mean_squared_error: 0.1975 - val_loss: 0.0183 - val_mean_squared_error: 0.0183\n",
      "Epoch 3/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0076 - val_mean_squared_error: 0.0076\n",
      "Epoch 4/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
      "Epoch 5/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
      "Epoch 6/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
      "Epoch 7/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
      "Epoch 8/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
      "Epoch 9/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
      "Epoch 10/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
      "Epoch 11/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
      "Epoch 12/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
      "Epoch 13/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
      "Epoch 14/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
      "Epoch 15/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 16/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 17/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
      "Epoch 18/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 19/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
      "Epoch 20/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
      "Epoch 21/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 22/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 23/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 24/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 25/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 26/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 27/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
      "Epoch 28/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 29/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 30/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 31/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 32/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 33/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 34/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 35/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 36/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 37/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 38/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 39/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
      "Epoch 40/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 41/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 42/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 43/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
      "Epoch 44/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 45/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 46/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 47/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 48/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 49/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 50/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Neural Net 1 time: 7.53 s\n",
      "0.3808726023149095\n"
     ]
    }
   ],
   "source": [
    "nn_mod_1 = Sequential()\n",
    "nn_mod_1.add(Input(shape=(16,)))\n",
    "nn_mod_1.add(Dense(15, activation='sigmoid'))\n",
    "nn_mod_1.add(Dense(1))\n",
    "\n",
    "opt = RMSprop()\n",
    "nn_mod_1.compile(optimizer=opt,\n",
    "                 loss = tf.keras.losses.MeanSquaredError(),\n",
    "               metrics=['mean_squared_error'])\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "nn_mod_1.fit(X_train_ctr_encoded,\n",
    "           y_train_ctr,\n",
    "           epochs=50,\n",
    "           validation_split=0.2)\n",
    "\n",
    "toc = time.time()\n",
    "print('Neural Net 1 time:', round(toc-tic, 2),'s')\n",
    "\n",
    "nn_pred = nn_mod_1.predict(X_test_ctr_encoded).ravel()\n",
    "print(OSR2(nn_pred, y_test_ctr, y_train_ctr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three Hidden Layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "106/106 [==============================] - 1s 2ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
      "Epoch 2/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
      "Epoch 3/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
      "Epoch 4/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 5/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
      "Epoch 6/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
      "Epoch 7/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
      "Epoch 8/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
      "Epoch 9/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
      "Epoch 10/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
      "Epoch 11/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
      "Epoch 12/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "Epoch 13/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
      "Epoch 14/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
      "Epoch 15/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
      "Epoch 16/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
      "Epoch 17/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
      "Epoch 18/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
      "Epoch 19/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
      "Epoch 20/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
      "Epoch 21/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
      "Epoch 22/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
      "Epoch 23/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 24/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
      "Epoch 25/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
      "Epoch 26/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 27/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
      "Epoch 28/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 29/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 30/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 31/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 32/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
      "Epoch 33/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
      "Epoch 34/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 35/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 36/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 37/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 38/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 39/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
      "Epoch 40/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
      "Epoch 41/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 42/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 43/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 44/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 45/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 46/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 47/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 48/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 49/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 50/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Neural Net 2 time: 7.07 s\n",
      "0.36990127255590133\n"
     ]
    }
   ],
   "source": [
    "nn_mod_2 = Sequential()\n",
    "nn_mod_2.add(Input(shape=(16,)))\n",
    "nn_mod_2.add(Dense(15, activation='sigmoid'))\n",
    "nn_mod_2.add(Dense(15, activation='sigmoid'))\n",
    "nn_mod_2.add(Dense(15, activation='sigmoid'))\n",
    "nn_mod_2.add(Dense(1))\n",
    "\n",
    "opt = RMSprop()\n",
    "nn_mod_2.compile(optimizer=opt,\n",
    "                 loss = tf.keras.losses.MeanSquaredError(),\n",
    "               metrics=['mean_squared_error'])\n",
    "\n",
    "tic = time.time()\n",
    "nn_mod_2.fit(X_train_ctr_encoded,\n",
    "           y_train_ctr,\n",
    "           epochs=50,\n",
    "           validation_split=0.2)\n",
    "toc = time.time()\n",
    "print('Neural Net 2 time:', round(toc-tic, 2),'s')\n",
    "\n",
    "nn_pred_2 = nn_mod_2.predict(X_test_ctr_encoded).ravel()\n",
    "print(OSR2(nn_pred_2, y_test_ctr, y_train_ctr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 hidden Layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "106/106 [==============================] - 1s 3ms/step - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 2/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
      "Epoch 3/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
      "Epoch 4/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 5/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 6/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 7/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 8/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 9/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
      "Epoch 10/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
      "Epoch 11/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
      "Epoch 12/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
      "Epoch 13/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 14/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 15/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 16/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 17/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 18/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
      "Epoch 19/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 20/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
      "Epoch 21/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 22/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 23/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 24/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 25/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 26/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 27/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
      "Epoch 28/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 29/50\n",
      "106/106 [==============================] - 0s 3ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
      "Epoch 30/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 31/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 32/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
      "Epoch 33/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 34/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
      "Epoch 35/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
      "Epoch 36/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
      "Epoch 37/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
      "Epoch 38/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
      "Epoch 39/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
      "Epoch 40/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 41/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 42/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
      "Epoch 43/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
      "Epoch 44/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 45/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 46/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 47/50\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 48/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 49/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 50/50\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Neural Net 2 time: 8.91 s\n",
      "0.36990127255590133\n"
     ]
    }
   ],
   "source": [
    "nn_mod_3 = Sequential()\n",
    "nn_mod_3.add(Input(shape=(16,)))\n",
    "nn_mod_3.add(Dense(15, activation='sigmoid'))\n",
    "nn_mod_3.add(Dense(15, activation='sigmoid'))\n",
    "nn_mod_3.add(Dense(15, activation='sigmoid'))\n",
    "nn_mod_3.add(Dense(15, activation='sigmoid'))\n",
    "nn_mod_3.add(Dense(15, activation='sigmoid'))\n",
    "nn_mod_3.add(Dense(15, activation='sigmoid'))\n",
    "nn_mod_3.add(Dense(15, activation='sigmoid'))\n",
    "nn_mod_3.add(Dense(15, activation='sigmoid'))\n",
    "nn_mod_3.add(Dense(15, activation='sigmoid'))\n",
    "nn_mod_3.add(Dense(15, activation='sigmoid'))\n",
    "nn_mod_3.add(Dense(1))\n",
    "\n",
    "opt = RMSprop()\n",
    "nn_mod_3.compile(optimizer=opt,\n",
    "                 loss = tf.keras.losses.MeanSquaredError(),\n",
    "               metrics=['mean_squared_error'])\n",
    "\n",
    "tic = time.time()\n",
    "nn_mod_3.fit(X_train_ctr_encoded,\n",
    "           y_train_ctr,\n",
    "           epochs=50,\n",
    "           validation_split=0.2)\n",
    "toc = time.time()\n",
    "print('Neural Net 2 time:', round(toc-tic, 2),'s')\n",
    "\n",
    "nn_pred_3 = nn_mod_2.predict(X_test_ctr_encoded).ravel()\n",
    "print(OSR2(nn_pred_3, y_test_ctr, y_train_ctr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "\n",
    "# lb = preprocessing.LabelBinarizer()\n",
    "# y_train_encoded = lb.fit_transform(y_train)\n",
    "# y_train_encoded\n",
    "\n",
    "\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# y_train_encoded = le.fit_transform(y_train)\n",
    "# y_train_encoded\n",
    "\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# enc = OneHotEncoder(handle_unknown='ignore')\n",
    "# y_train_encoded = enc.fit_transform(y_train.reshape(-1, 1))\n",
    "# y_train_encoded.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
